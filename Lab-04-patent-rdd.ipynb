{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 4253 / 5253 - Lab #4 - Patent Problem with Spark RDD - SOLUTION\n",
    "<div>\n",
    " <h2> CSCI 4283 / 5253 \n",
    "  <IMG SRC=\"https://www.colorado.edu/cs/profiles/express/themes/cuspirit/logo.png\" WIDTH=50 ALIGN=\"right\"/> </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [Spark cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf) is useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=SparkConf().setAppName(\"Lab4-rdd\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cite75_99.txt.gz already exists, skipping download.\n",
      "apat63_99.txt.gz already exists, skipping download.\n",
      "All files ready!\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# URLs from your makefile\n",
    "urls = [\n",
    "    'https://github.com/cu-csci-4253-datacenter/lab4-pyspark-patent-data/raw/master/cite75_99.txt.gz',\n",
    "    'https://github.com/cu-csci-4253-datacenter/lab4-pyspark-patent-data/raw/master/apat63_99.txt.gz'\n",
    "]\n",
    "\n",
    "# Corresponding local filenames\n",
    "filenames = [\n",
    "    'cite75_99.txt.gz',\n",
    "    'apat63_99.txt.gz'\n",
    "]\n",
    "\n",
    "# Download files with progress\n",
    "for url, filename in zip(urls, filenames):\n",
    "    if not os.path.exists(filename):\n",
    "        print(f'Downloading {filename}...')\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "        print(f'{filename} downloaded successfully!')\n",
    "        print(f'File size: {os.path.getsize(filename) / (1024*1024):.2f} MB')\n",
    "    else:\n",
    "        print(f'{filename} already exists, skipping download.')\n",
    "\n",
    "print('All files ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PySpark and RDD's on the https://coding.csel.io machines is slow -- most of the code is executed in Python and this is much less efficient than the java-based code using the PySpark dataframes. Be patient and trying using `.cache()` to cache the output of joins. You may want to start with a reduced set of data before running the full task. You can use the `sample()` method to extract just a sample of the data or use "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two RDD's are called \"rawCitations\" and \"rawPatents\" because you probably want to process them futher (e.g. convert them to integer types, etc). \n",
    "\n",
    "The `textFile` function returns data in strings. This should work fine for this lab.\n",
    "\n",
    "Other methods you use might return data in type `Byte`. If you haven't used Python `Byte` types before, google it. You can convert a value of `x` type byte into e.g. a UTF8 string using `x.decode('uft-8')`. Alternatively, you can use the `open` method of the gzip library to read in all the lines as UTF-8 strings like this:\n",
    "```\n",
    "import gzip\n",
    "with gzip.open('cite75_99.txt.gz', 'rt',encoding='utf-8') as f:\n",
    "    rddCitations = sc.parallelize( f.readlines() )\n",
    "```\n",
    "This is less efficient than using `textFile` because `textFile` would use the underlying HDFS or other file system to read the file across all the worker nodes while the using `gzip.open()...readlines()` will read all the data in the frontend and then distribute it to all the worker nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddCitations = sc.textFile(\"cite75_99.txt.gz\")\n",
    "rddPatents = sc.textFile(\"apat63_99.txt.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks like the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"CITING\",\"CITED\"',\n",
       " '3858241,956203',\n",
       " '3858241,1324234',\n",
       " '3858241,3398406',\n",
       " '3858241,3557384']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddCitations.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"PATENT\",\"GYEAR\",\"GDATE\",\"APPYEAR\",\"COUNTRY\",\"POSTATE\",\"ASSIGNEE\",\"ASSCODE\",\"CLAIMS\",\"NCLASS\",\"CAT\",\"SUBCAT\",\"CMADE\",\"CRECEIVE\",\"RATIOCIT\",\"GENERAL\",\"ORIGINAL\",\"FWDAPLAG\",\"BCKGTLAG\",\"SELFCTUB\",\"SELFCTLB\",\"SECDUPBD\",\"SECDLWBD\"',\n",
       " '3070801,1963,1096,,\"BE\",\"\",,1,,269,6,69,,1,,0,,,,,,,',\n",
       " '3070802,1963,1096,,\"US\",\"TX\",,1,,2,6,63,,0,,,,,,,,,',\n",
       " '3070803,1963,1096,,\"US\",\"IL\",,1,,2,6,63,,9,,0.3704,,,,,,,',\n",
       " '3070804,1963,1096,,\"US\",\"OH\",,1,,2,6,63,,3,,0.6667,,,,,,,']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddPatents.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations_parsed = rddCitations.map(lambda line: line.split(\",\")) \\\n",
    "                               .map(lambda x: (x[0].strip('\"'), x[1].strip('\"')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing patents data into (patent_id, patent_data_list)\n",
    "patents_parsed = rddPatents.map(lambda line: line.split(\",\")) \\\n",
    "                           .map(lambda x: (x[0].strip('\"'), x[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pairs of patents data and Extracting state info\n",
    "patent_states = patents_parsed.map(lambda x: (x[0], x[1][4].strip('\"') if len(x[1]) > 4 and x[1][4].strip('\"') != '' else None)) \\\n",
    "                              .filter(lambda x: x[1] is not None and x[1] != 'null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining citations with citing patent states\n",
    "citations_with_citing_state = citations_parsed.join(patent_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging for next join\n",
    "citations_rearranged = citations_with_citing_state.map(lambda x: (x[1][0], (x[0], x[1][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a join with cited patent states\n",
    "citations_with_both_states = citations_rearranged.join(patent_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out the same state citations\n",
    "same_state_cites = citations_with_both_states.filter(lambda x: x[1][0][1] == x[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting same state citations per patent\n",
    "from operator import add\n",
    "same_state_counts = same_state_cites.map(lambda x: (x[1][0][0], 1)).reduceByKey(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left Join with all the patents\n",
    "patents_with_counts = patents_parsed.leftOuterJoin(same_state_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out only US patents\n",
    "us_patents = patents_with_counts.filter(lambda x: len(x[1][0]) > 3 and x[1][0][3].strip('\"') == 'US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formating and sorting results\n",
    "us_patents_formatted = us_patents.map(lambda x: (\n",
    "    x[0],  # patent_id\n",
    "    x[1][0],  # patent_data \n",
    "    x[1][1] if x[1][1] is not None else 0  # same_state_count\n",
    ")).sortBy(lambda x: (-x[2], x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching top 10 results\n",
    "top_10 = us_patents_formatted.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 10 US PATENTS BY SAME-STATE CITATIONS\n",
      "========================================================================================================================================================================================================\n",
      "PATENT  GYEAR GDATE   APPYEAR COUNTRY POSTATE ASSIGNEE    ASSCODE CLAIMS NCLASS CAT  SUBCAT CMADE  CRECEIVE RATIOCIT GENERAL  ORIGINAL FWDAPLAG BCKGTLAG SELFCTUB SELFCTLB SECDUPBD SECDLWBD SAME_STATE \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "5959466 1999  14515   1997    US      CA      5310        2       null   326    4    46     159    0        1        null     0.6186   null     4.8868   0.0455   0.044    null     null     125        \n",
      "5983822 1999  14564   1998    US      TX      569900      2       null   114    5    55     200    0        0.995    null     0.7201   null     12.45    0        0        null     null     103        \n",
      "6008204 1999  14606   1998    US      CA      749584      2       null   514    3    31     121    0        1        null     0.7415   null     5        0.0085   0.0083   null     null     100        \n",
      "5952345 1999  14501   1997    US      CA      749584      2       null   514    3    31     118    0        1        null     0.7442   null     5.1102   0        0        null     null     98         \n",
      "5958954 1999  14515   1997    US      CA      749584      2       null   514    3    31     116    0        1        null     0.7397   null     5.181    0        0        null     null     96         \n",
      "5998655 1999  14585   1998    US      CA      null        1       null   560    1    14     114    0        1        null     0.7387   null     5.1667   null     null     null     null     96         \n",
      "5936426 1999  14466   1997    US      CA      5310        2       null   326    4    46     178    0        1        null     0.58     null     11.2303  0.0765   0.073    null     null     94         \n",
      "5739256 1998  13983   1995    US      CA      70060       2       15     528    1    15     453    0        1        null     0.8232   null     15.1104  0.1124   0.1082   null     null     90         \n",
      "5913855 1999  14417   1997    US      CA      733846      2       null   606    3    32     242    0        1        null     0.7403   null     8.3595   0        0        null     null     90         \n",
      "5925042 1999  14445   1997    US      CA      733846      2       null   606    3    32     242    0        1        null     0.7382   null     8.3471   0        0        null     null     90         \n"
     ]
    }
   ],
   "source": [
    "# Fixing Proper column alignment with exact widths\n",
    "print(\"TOP 10 US PATENTS BY SAME-STATE CITATIONS\")\n",
    "print(\"=\" * 200)\n",
    "\n",
    "# Defining exact column widths for perfect alignment\n",
    "col_widths = [8, 6, 8, 8, 8, 8, 12, 8, 7, 7, 5, 7, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 11]\n",
    "header = ['PATENT', 'GYEAR', 'GDATE', 'APPYEAR', 'COUNTRY', 'POSTATE', 'ASSIGNEE', 'ASSCODE', \n",
    "          'CLAIMS', 'NCLASS', 'CAT', 'SUBCAT', 'CMADE', 'CRECEIVE', 'RATIOCIT', 'GENERAL', \n",
    "          'ORIGINAL', 'FWDAPLAG', 'BCKGTLAG', 'SELFCTUB', 'SELFCTLB', 'SECDUPBD', 'SECDLWBD', 'SAME_STATE']\n",
    "\n",
    "# Printing header with exact spacing\n",
    "header_line = \"\"\n",
    "for i, col in enumerate(header):\n",
    "    header_line += f\"{col:<{col_widths[i]}}\"\n",
    "print(header_line)\n",
    "\n",
    "# Printing separator\n",
    "print(\"-\" * sum(col_widths))\n",
    "\n",
    "# Printing data rows with exact spacing\n",
    "for patent_id, patent_data, count in top_10:\n",
    "    # Cleaning and prepare data\n",
    "    clean_data = [patent_id]  # Start with patent ID\n",
    "    \n",
    "    # Adding patent fields (first 22 fields)\n",
    "    for i, field in enumerate(patent_data[:22]):\n",
    "        field = field.strip('\"')\n",
    "        if field == '' or field is None:\n",
    "            clean_data.append('null')\n",
    "        else:\n",
    "            clean_data.append(field)\n",
    "    \n",
    "    # Adding same-state count\n",
    "    clean_data.append(str(count))\n",
    "    \n",
    "    # Formating row with exact column widths\n",
    "    row_line = \"\"\n",
    "    for i, value in enumerate(clean_data):\n",
    "        if i < len(col_widths):\n",
    "            if len(str(value)) > col_widths[i] - 1:\n",
    "                value = str(value)[:col_widths[i] - 2] + \"..\"\n",
    "            row_line += f\"{str(value):<{col_widths[i]}}\"\n",
    "    \n",
    "    print(row_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, they are a single string with multiple CSV's. You will need to convert these to (K,V) pairs, probably convert the keys to `int` and so on. You'll need to `filter` out the header string as well since there's no easy way to extract all the lines except the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
